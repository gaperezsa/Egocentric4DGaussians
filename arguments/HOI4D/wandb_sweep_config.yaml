
# wandb_sweep_config.yaml
# W&B Hyperparameter Sweep Configuration
# 
# Usage:
#   1. Initialize sweep: wandb sweep wandb_sweep_config.yaml
#   2. Run agent: wandb agent <sweep_id>
#

program: train_dynamic_depth.py
method: grid  # or 'random' for random search, 'bayes' for bayesian optimization
name: "egocentric_4d_gaussian_hparam_sweep"

command:
  - ${env}
  - python
  - ${program}
  - --configs
  - arguments/HOI4D/default.py
  - --source_path
  - /home/gperezsantamaria/gperezsantamaria2/Egocentric4DGaussians/data/automatic_data_extraction_testing/with_monst3r/Video1/colmap
  - --expname
  - ${env}

# ========================================================================
# SWEEPABLE PARAMETERS (W&B will override config file values)
# ========================================================================

parameters:
  # ====== Stage Iterations ======
  background_depth_iterations:
    values: [300, 500, 1000]
    # ^ Short: 300, Medium: 500, Long: 1000
  
  background_RGB_iterations:
    values: [200, 300, 500]
    # ^ Shorter RGB stage than depth

  dynamics_depth_iterations:
    values: [100, 200, 400]
    # ^ Dynamic point cloud optimization

  dynamics_RGB_iterations:
    values: [100, 200, 300]
    # ^ RGB quality on dynamics

  fine_iterations:
    values: [200, 300, 500]
    # ^ Final fine-tuning

  # ====== Learning Rates ======
  batch_size:
    values: [2, 4, 8]
    # ^ Memory/convergence tradeoff

  static_position_lr_init:
    values: [0.008, 0.016, 0.032]
    # ^ Higher = faster convergence, lower = more stable

  dynamic_position_lr_init:
    values: [0.0008, 0.0016, 0.0032]
    # ^ Usually smaller than static

  # ====== Loss Weights ======
  general_depth_weight:
    values: [0.001, 0.01, 0.1]
    # ^ Depth supervision strength
    # ^ Current: 0.01 (too small! Consider increasing to 0.1)

  chamfer_weight:
    values: [25.0, 50.0, 100.0]
    # ^ Dynamic object point cloud matching
    # ^ Current: 50.0 (seems well-calibrated, range 21-29 observed)

  normal_loss_weight:
    values: [0.01, 0.05, 0.1]
    # ^ Normal consistency
    # ^ Current: 0.05

  ssim_weight:
    values: [0.0, 0.1, 0.2]
    # ^ SSIM loss in fine stage
    # ^ Current: 0.1 (set to 0.0 to disable)

  plane_tv_weight:
    values: [0.00001, 0.0001, 0.001]
    # ^ Space-time TV regularization
    # ^ Current: 0.0001

  # ====== Densification & Pruning ======
  densification_interval:
    values: [50, 100, 200]
    # ^ How often to add/remove Gaussians

  pruning_interval:
    values: [100, 200, 400]
    # ^ How often to remove bad Gaussians

# ========================================================================
# SUMMARY: What this sweep will test
# ========================================================================
#
# Total combinations: 3^10 = 59,049 (with grid method)
# 
# Key hypotheses:
# 1. Is general_depth_weight too small? Test 0.001→0.1
# 2. Does batch_size affect convergence? Test 2→8
# 3. Are learning rates stable? Test static 0.008→0.032
# 4. Best RGB stage length? Test dynamics_RGB 100→300
# 5. Chamfer weight sensitivity? Test 25→100
#
# Cost estimate (assuming 1 run = 5 min):
# - Full grid (59,049 runs): 205 days (not practical!)
# - Recommended: Random search with 50-100 runs
# - Or: Use bayes method for smart sampling
#

